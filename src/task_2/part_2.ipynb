{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "id": "9dd51307648ca888"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_in = pd.read_csv(\"../../data/train_in.csv\", header=None)\n",
    "test_in = pd.read_csv(\"../../data/test_in.csv\", header=None)\n",
    "train_out = pd.read_csv(\"../../data/train_out.csv\", header=None)\n",
    "test_out = pd.read_csv(\"../../data/test_out.csv\", header=None)"
   ],
   "id": "d5176f9702be0b21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train = train_in.to_numpy(dtype=np.float32)\n",
    "X_test = test_in.to_numpy(dtype=np.float32)\n",
    "y_train = train_out.to_numpy(dtype=np.int64).ravel()\n",
    "y_test = test_out.to_numpy(dtype=np.int64).ravel()"
   ],
   "id": "751f7717ba5fee22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def add_bias(X: np.ndarray) -> np.ndarray:\n",
    "    ones = np.ones((X.shape[0], 1), dtype=X.dtype)\n",
    "    return np.hstack([X, ones])"
   ],
   "id": "1aeca803504b2839"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train = add_bias(X_train)  # (N_train, 257)\n",
    "X_test  = add_bias(X_test)\n",
    "num_classes = 10\n",
    "num_features = X_train.shape[1]\n",
    "rng = np.random.default_rng(2)"
   ],
   "id": "e70ef9f6b9ddb263"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate(X: np.ndarray, y: np.ndarray, W: np.ndarray):\n",
    "    no_of_examples = X.shape[0]\n",
    "    scores = X @ W\n",
    "    predictions = np.argmax(scores, axis=1)\n",
    "\n",
    "    accuracy = (predictions == y).mean()\n",
    "    epoch_loss = 1.0 - accuracy\n",
    "    Y_true = one_hot(y, num_classes)\n",
    "    Y_pred = one_hot(predictions, num_classes)\n",
    "    mistakes = (predictions != y).astype(np.float32)[:, None]\n",
    "    epoch_gradient = (Y_pred - Y_true) * mistakes / no_of_examples\n",
    "\n",
    "    return accuracy, epoch_loss, epoch_gradient"
   ],
   "id": "d8ed038ff54280c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def one_hot(y: np.ndarray, no_of_classes: int) -> np.ndarray:\n",
    "    one_hot_encoding = np.zeros((y.shape[0], no_of_classes), dtype=np.float64)\n",
    "    one_hot_encoding[np.arange(y.shape[0]), y] = 1.0\n",
    "    return one_hot_encoding"
   ],
   "id": "2218a36b708fe2ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def softmax(X, axis=1):\n",
    "    X = X - np.max(X, axis=axis, keepdims=True)  # stabilize per row\n",
    "    e_X = np.exp(X)\n",
    "    return e_X / np.sum(e_X, axis=axis, keepdims=True)"
   ],
   "id": "ec1972d7fe5c7114"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "epochs = 100\n",
    "lr = 0.01\n",
    "\n",
    "W = rng.normal(0, 0.01, size=(num_features, num_classes))\n",
    "train_acc_hist, train_loss_hist = [], []\n",
    "test_acc_hist, test_loss_hist = [], []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    X = X_train\n",
    "    y = y_train\n",
    "\n",
    "    train_acc, train_loss, epoch_gradient = evaluate(X, y, W)\n",
    "    W -= lr * (X.T @ epoch_gradient)\n",
    "\n",
    "    test_acc, test_loss, _ = evaluate(X_test, y_test, W)\n",
    "\n",
    "    train_acc_hist.append(train_acc)\n",
    "    train_loss_hist.append(train_loss)\n",
    "\n",
    "    test_acc_hist.append(test_acc)\n",
    "    test_loss_hist.append(test_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:03d} | \"\n",
    "        f\"train acc: {train_acc:.4f} | train loss: {train_loss:.4f} | \"\n",
    "        f\"test acc: {test_acc:.4f} | test loss: {test_loss:.4f}\"\n",
    "    )\n",
    "    # break\n",
    "\n",
    "    if train_acc == 1:\n",
    "        break"
   ],
   "id": "3ece433c314416f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(len(train_acc_hist)), train_acc_hist, label=\"Train\", color=\"tab:blue\")\n",
    "plt.plot(range(len(test_acc_hist)), test_acc_hist,  label=\"Test\",  color=\"tab:orange\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy per epoch(Train vs Test)\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(len(train_loss_hist)), train_loss_hist, label=\"Train\", color=\"tab:blue\")\n",
    "plt.plot(range(len(test_loss_hist)), test_loss_hist,  label=\"Test\",  color=\"tab:orange\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss per epoch(Train vs Test)\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ],
   "id": "dcf65e44760332d5"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
