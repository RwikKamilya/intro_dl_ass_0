{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ],
   "id": "cf5e9b4df617ea95"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_in = pd.read_csv(\"../../data/train_in.csv\", header=None)\n",
    "test_in = pd.read_csv(\"../../data/test_in.csv\", header=None)\n",
    "train_out = pd.read_csv(\"../../data/train_out.csv\", header=None)\n",
    "test_out = pd.read_csv(\"../../data/test_out.csv\", header=None)"
   ],
   "id": "ddb285974b24f45c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train = train_in.to_numpy(dtype=np.float64)\n",
    "X_test = test_in.to_numpy(dtype=np.float64)\n",
    "y_train = train_out.to_numpy(dtype=np.int64).ravel()\n",
    "y_test = test_out.to_numpy(dtype=np.int64).ravel()"
   ],
   "id": "7f6f24477118fd73"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_classes = 10\n",
    "no_of_examples = X_train.shape[0]\n",
    "num_features = X_train.shape[1]\n",
    "\n",
    "rng = np.random.default_rng(2)\n",
    "W = rng.normal(0, 0.01, size=(num_features, num_classes)).astype(np.float64)\n",
    "b = rng.normal(0, 0.01, size=(num_classes,)).astype(np.float64)\n",
    "\n",
    "train_acc_hist, train_loss_hist = [], []\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.01\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    total_epoch_loss = 0.0\n",
    "    correct_per_epoch = 0\n",
    "\n",
    "    sum_grad_W = 0\n",
    "    sum_grad_b = 0\n",
    "\n",
    "    for example in range(no_of_examples):\n",
    "        x = X_train[example]    # (256,)\n",
    "        y_true = y_train[example]   # int (0-9)\n",
    "\n",
    "        scores = b + W.T @ x    # (10,)\n",
    "        probabilities = softmax(scores) # (10,)\n",
    "\n",
    "        prediction = np.argmax(probabilities)\n",
    "        if prediction == y_true:\n",
    "            correct_per_epoch += 1\n",
    "\n",
    "        y_vec = np.zeros(num_classes, dtype=np.float64)\n",
    "        y_vec[y_true] = 1.0\n",
    "\n",
    "        class_wise_error = probabilities - y_vec\n",
    "\n",
    "        example_loss = np.sum(class_wise_error ** 2)\n",
    "        total_epoch_loss += float(example_loss)\n",
    "\n",
    "        grad_b = 2 * class_wise_error\n",
    "        grad_W = 2 * np.outer(x, class_wise_error)\n",
    "\n",
    "        sum_grad_W += grad_W\n",
    "        sum_grad_b += grad_b\n",
    "\n",
    "        # W -= lr * grad_W\n",
    "        # b -= lr * grad_b\n",
    "\n",
    "    W -= lr * (sum_grad_W / no_of_examples)\n",
    "    b -= lr * (sum_grad_b / no_of_examples)\n",
    "\n",
    "    mean_loss = total_epoch_loss / no_of_examples\n",
    "    epoch_accuracy = correct_per_epoch / no_of_examples\n",
    "\n",
    "    train_acc_hist.append(epoch_accuracy)\n",
    "    train_loss_hist.append(mean_loss)\n",
    "\n",
    "    if epoch_accuracy == 1:\n",
    "        break\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train loss: {mean_loss:.4f} | train acc: {epoch_accuracy:.4f}\")"
   ],
   "id": "6d3d5b652b1f157a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure()\n",
    "plt.plot(range(len(train_acc_hist)), train_acc_hist, label=\"train\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy per epoch\")\n",
    "plt.grid(True); plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(len(train_loss_hist)), train_loss_hist, label=\"train\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE (probs vs one-hot)\")\n",
    "plt.title(\"Loss per epoch\")\n",
    "plt.grid(True); plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "id": "9d0781d8351b1aad"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
